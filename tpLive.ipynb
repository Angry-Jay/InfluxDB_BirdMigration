{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2j9m3kslk4",
   "metadata": {},
   "source": [
    "## Partie 0 : Introduction aux Bases de Données Time-Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kd9l5mbtwih",
   "metadata": {},
   "source": [
    "### 0.1 Qu'est-ce qu'une donnée time-series ?\n",
    "\n",
    "Une donnée time-series (série temporelle) est une séquence de points de données indexés dans l'ordre temporel. Exemples courants :\n",
    "\n",
    "- Capteurs IoT : température, pression, humidité mesurées toutes les secondes\n",
    "- Tracking d'animaux : positions GPS avec timestamp (notre cas)\n",
    "- Finance : cours de bourse, transactions bancaires\n",
    "- Monitoring IT : métriques serveur (CPU, RAM, réseau)\n",
    "\n",
    "Caractéristiques clés :\n",
    "- Chaque point a un timestamp précis\n",
    "- Les données arrivent généralement dans l'ordre chronologique\n",
    "- Souvent volumineuses (millions de points)\n",
    "- Les requêtes portent fréquemment sur des intervalles de temps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qppqf89vp3e",
   "metadata": {},
   "source": [
    "### 0.2 Pourquoi InfluxDB plutôt que MongoDB ou MySQL ?\n",
    "\n",
    "| Critère | MySQL | MongoDB | InfluxDB |\n",
    "|---------|-------|---------|----------|\n",
    "| Structure | Tables relationnelles | Documents JSON | Mesures + tags + fields + time |\n",
    "| Indexation temporelle | Index B-tree standard | Index classique | Index temporel natif (TSM) |\n",
    "| Agrégations temporelles | Lent | Acceptable | Très rapide |\n",
    "| Compression | Faible | Moyenne | Très élevée (10-20x) |\n",
    "| Cas d'usage | E-commerce, CRM | Applications web | **Monitoring, IoT, tracking** |\n",
    "\n",
    "Pour notre dataset de migration d'oiseaux :\n",
    "- 89 867 points temporels → structure time-series\n",
    "- Requêtes fréquentes par intervalle de temps\n",
    "- Besoin d'agrégations temporelles (distance parcourue par jour)\n",
    "- Compression importante (données géographiques répétitives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v46bzb1lhek",
   "metadata": {},
   "source": [
    "### 0.3 Concepts Clés d'InfluxDB\n",
    "\n",
    "InfluxDB organise les données différemment des bases relationnelles ou documents :\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│ MEASUREMENT (table)                                          │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│ Tags (indexés)          │ Fields (valeurs)    │ Timestamp   │\n",
    "│ ======================= │ =================== │ =========== │\n",
    "│ bird_id: \"91732A\"       │ latitude: 61.24     │ 2009-05-27  │\n",
    "│ tag_id: 91732           │ longitude: 24.58    │ 14:00:00    │\n",
    "│                         │ vegetation: 0.96    │             │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**1. Measurement** : nom de la \"table\" (ex: `bird_migration`)\n",
    "\n",
    "**2. Tags** : métadonnées indexées\n",
    "   - Chaînes de caractères uniquement\n",
    "   - Cardinalité modérée recommandée (< 100k valeurs uniques)\n",
    "   - Utilisés pour filtrer : `WHERE bird_id = \"91732A\"`\n",
    "   - Exemples : bird_id, sensor_type, region\n",
    "\n",
    "**3. Fields** : valeurs mesurées\n",
    "   - Peuvent être de tout type (float, int, string, bool)\n",
    "   - Non indexés → ne pas filtrer dessus si possible\n",
    "   - Exemples : latitude, longitude, température, vitesse\n",
    "\n",
    "**4. Timestamp** : horodatage du point (nanoseconde precision)\n",
    "\n",
    "Règle d'or pour choisir tag vs field :\n",
    "- Tag si vous filtrez souvent dessus (`WHERE ...`)\n",
    "- Field si c'est une valeur mesurée/calculée\n",
    "- Tag seulement si cardinalité raisonnable (éviter timestamps, IDs uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52af640",
   "metadata": {},
   "source": [
    "## Partie 1 : Installation et Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66859f60",
   "metadata": {},
   "source": [
    "### 1.1 Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# InfluxDB\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "# Kaggle\n",
    "import kagglehub\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce743b0",
   "metadata": {},
   "source": [
    "### 1.2 Configuration InfluxDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2tmvlj3q645",
   "metadata": {},
   "source": [
    "Configuration requise :\n",
    "- **URL** : adresse du serveur InfluxDB (ici dans Docker : `http://influxdb2:8086`)\n",
    "- **Token** : clé d'authentification (admin-token configuré dans docker-compose)\n",
    "- **Organisation** : espace de travail logique\n",
    "- **Bucket** : \"base de données\" où stocker les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2207e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration InfluxDB\n",
    "INFLUX_URL = \"http://influxdb2:8086\" \n",
    "INFLUX_TOKEN = \"admin-token\"\n",
    "INFLUX_ORG = \"fil-A3-back-bigData\"\n",
    "INFLUX_BUCKET = \"animal-tracking\"  \n",
    "\n",
    "# Connexion au client\n",
    "client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG)\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "query_api = client.query_api()\n",
    "\n",
    "print(\"Client InfluxDB connecté\")\n",
    "print(f\"  Bucket: {INFLUX_BUCKET}\")\n",
    "print(f\"  Organisation: {INFLUX_ORG}\")\n",
    "\n",
    "# Vérification de la connexion\n",
    "try:\n",
    "    if client.ping():\n",
    "        print(\"Serveur InfluxDB répond\")\n",
    "    else:\n",
    "        print(\"Serveur ne répond pas\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e568ede",
   "metadata": {},
   "source": [
    "## Partie 2 : Chargement et Exploration des Données\n",
    "\n",
    "Comprendre la structure des données et identifier ce qui en fait une série temporelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff07ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Download the Movebank animal tracking dataset\n",
    "path = \"pulkit8595/movebank-animal-tracking\"\n",
    "print(\"Downloading dataset from Kaggle...\")\n",
    "dataset_path = kagglehub.dataset_download(path)\n",
    "print(f\"Dataset downloaded to: {dataset_path}\")\n",
    "\n",
    "# List files in the dataset\n",
    "print(\"\\nFiles in dataset:\")\n",
    "for file in os.listdir(dataset_path):\n",
    "    file_size = os.path.getsize(os.path.join(dataset_path, file)) / 1024  # KB\n",
    "    print(f\"  - {file} ({file_size:.2f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_path, \"migration_original.csv\"))\n",
    "\n",
    "print(\"Dataset loaded into DataFrame\")\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informations sur le dataset\n",
    "print(\"Informations sur le dataset:\")\n",
    "print(df.info())\n",
    "print(\"\\n Statistiques descriptives:\")\n",
    "print(df.describe())\n",
    "print(\"\\n Valeurs manquantes:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4o1aggor98p",
   "metadata": {},
   "source": [
    "### 2.1 Analyse de cardinalité (crucial pour le design du schéma)\n",
    "\n",
    "La cardinalité (nombre de valeurs distinctes) détermine si une colonne doit être un tag ou un field dans InfluxDB :\n",
    "- Cardinalité basse (< 100 valeurs) → Bon candidat pour tag\n",
    "- Cardinalité moyenne (100-100k valeurs) → Acceptable comme tag si filtrage fréquent\n",
    "- Cardinalité haute (> 100k valeurs) → NE PAS mettre en tag (explosion des index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nr2x2vl0dgs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de cardinalité pour chaque colonne\n",
    "print(\"=\" * 70)\n",
    "print(\"ANALYSE DE CARDINALITÉ\".center(70))\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Colonne':<50} {'Cardinalité':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for col in df.columns:\n",
    "    cardinality = df[col].nunique()\n",
    "    total = len(df)\n",
    "    percentage = (cardinality / total) * 100\n",
    "    \n",
    "    # Indicateur selon le type de cardinalité\n",
    "    if cardinality == 1:\n",
    "        indicator = \"CONSTANTE\"\n",
    "    elif cardinality < 100:\n",
    "        indicator = \"BASSE (bon tag)\"\n",
    "    elif cardinality < 10000:\n",
    "        indicator = \"MOYENNE (tag ok)\"\n",
    "    elif cardinality == total:\n",
    "        indicator = \"UNIQUE (PK)\"\n",
    "    else:\n",
    "        indicator = \"HAUTE (field)\"\n",
    "    \n",
    "    print(f\"{col:<50} {cardinality:>10,} ({percentage:>5.1f}%)  {indicator}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p21yel8d33i",
   "metadata": {},
   "source": [
    "### 2.2 Analyse temporelle\n",
    "\n",
    "À quelle fréquence les oiseaux sont-ils trackés ? Est-ce régulier ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h5iy4sqaar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ANALYSE TEMPORELLE\".center(70))\n",
    "print(\"=\" * 70)\n",
    "print(f\"Date de début    : {df['timestamp'].min()}\")\n",
    "print(f\"Date de fin      : {df['timestamp'].max()}\")\n",
    "print(f\"Durée totale     : {(df['timestamp'].max() - df['timestamp'].min()).days} jours\")\n",
    "print(f\"Nombre de points : {len(df):,}\")\n",
    "print()\n",
    "\n",
    "# Analyser la fréquence de tracking\n",
    "sample_bird = df['individual-local-identifier'].value_counts().index[0]\n",
    "bird_data = df[df['individual-local-identifier'] == sample_bird].sort_values('timestamp')\n",
    "intervals = bird_data['timestamp'].diff().dt.total_seconds() / 3600\n",
    "\n",
    "print(f\"Fréquence de tracking (oiseau exemple: {sample_bird}):\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Intervalle moyen : {intervals.mean():.1f} heures\")\n",
    "print(f\"  Intervalle médian: {intervals.median():.1f} heures\")\n",
    "print(f\"  Min / Max        : {intervals.min():.1f}h / {intervals.max():.1f}h\")\n",
    "print()\n",
    "print(\"Tracking irrégulier (typique des données GPS réelles)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exxx1uusr9w",
   "metadata": {},
   "source": [
    "### 2.3 Distribution des données par oiseau\n",
    "\n",
    "Tous les oiseaux sont-ils trackés de manière équivalente ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xty9w4twmdk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution du nombre de points par oiseau\n",
    "bird_counts = df['individual-local-identifier'].value_counts()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DISTRIBUTION DU TRACKING PAR OISEAU\".center(70))\n",
    "print(\"=\" * 70)\n",
    "print(f\"Nombre d'oiseaux   : {len(bird_counts)}\")\n",
    "print(f\"Points par oiseau  : {bird_counts.mean():.0f} ± {bird_counts.std():.0f} (moyenne ± écart-type)\")\n",
    "print(f\"Min/Max            : {bird_counts.min()} / {bird_counts.max()} points\")\n",
    "print()\n",
    "print(\"Top 10 oiseaux les plus trackés:\")\n",
    "print(\"-\" * 70)\n",
    "for i, (bird_id, count) in enumerate(bird_counts.head(10).items(), 1):\n",
    "    bar = \"█\" * int(count / bird_counts.max() * 40)\n",
    "    print(f\"{i:2}. {bird_id:<15} {count:>5,} points {bar}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3ds8muxsyb",
   "metadata": {},
   "source": [
    "### 2.4 Visualisation géographique rapide\n",
    "\n",
    "Où se trouvent les oiseaux ? Migration visible ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4hntsmhw9cp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données\n",
    "sample_df = df.iloc[::5].copy()\n",
    "sample_df['date'] = pd.to_datetime(sample_df['timestamp'])\n",
    "sample_df['bird_id'] = sample_df['individual-local-identifier']\n",
    "\n",
    "\n",
    "# Visualisation des trajectoires d'oiseaux\n",
    "fig = px.scatter_geo(sample_df,\n",
    "                     lat='location-lat',\n",
    "                     lon='location-long',\n",
    "                     color='bird_id',\n",
    "                     hover_data=['date', 'bird_id'],\n",
    "                     title='Migration Patterns - Bird Tracking Data',\n",
    "                     projection='natural earth')\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    showlegend=True,\n",
    "    geo=dict(\n",
    "        showland=True,\n",
    "        landcolor='rgb(243, 243, 243)',\n",
    "        coastlinecolor='rgb(204, 204, 204)',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Statistiques par oiseau\n",
    "print(f\"Dataset échantillonné: {len(sample_df):,} points\")\n",
    "print(f\"Nombre d'oiseaux: {sample_df['bird_id'].nunique()}\")\n",
    "print(f\"Période: {sample_df['date'].min()} → {sample_df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd552f9a",
   "metadata": {},
   "source": [
    "## Partie 3 : Nettoyage des Données\n",
    "\n",
    "Préparer les données pour InfluxDB en supprimant les colonnes inutiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7iz6k2zqkd9",
   "metadata": {},
   "source": [
    "Stratégie de nettoyage :\n",
    "\n",
    "1. Supprimer les colonnes 100% vides (aucune valeur utile)\n",
    "   - Exemple : `manually-marked-outlier`, `NCEP NARR SFC Vegetation at Surface`\n",
    "   - Ces colonnes ajouteraient des fields inutiles dans InfluxDB\n",
    "\n",
    "2. Garder les colonnes redondantes mais utiles\n",
    "   - `visible` et `visible.1` semblent dupliquées mais gardons-les pour l'instant\n",
    "   - Si vraiment identiques, on pourra supprimer après vérification\n",
    "\n",
    "3. Renommer les colonnes pour la lisibilité\n",
    "   - `ECMWF Interim Full Daily...` → `vegetation_cover_low/high`\n",
    "   - Noms courts = queries Flux plus lisibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zlzucxigrhj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les colonnes 100% vides\n",
    "columns_to_drop = df.columns[df.isnull().all()].tolist()\n",
    "df_clean = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Renommer les colonnes de végétation pour plus de clarté\n",
    "df_clean = df_clean.rename(columns={\n",
    "    'ECMWF Interim Full Daily Invariant Low Vegetation Cover': 'vegetation_cover_low',\n",
    "    'ECMWF Interim Full Daily Invariant High Vegetation Cover': 'vegetation_cover_high'\n",
    "})\n",
    "\n",
    "print(f\"Colonnes supprimées (100% vides): {len(columns_to_drop)}\")\n",
    "print(f\"Colonnes renommées: vegetation_cover_low/high\")\n",
    "print(f\"Dataset nettoyé: {df_clean.shape[0]:,} lignes × {df_clean.shape[1]} colonnes\")\n",
    "\n",
    "# Vérifier valeurs manquantes restantes\n",
    "null_counts = df_clean.isnull().sum()\n",
    "remaining_nulls = null_counts[null_counts > 0]\n",
    "if len(remaining_nulls) > 0:\n",
    "    print(f\"\\nValeurs manquantes restantes:\")\n",
    "    for col, count in remaining_nulls.items():\n",
    "        print(f\"  {col}: {count:,} ({count/len(df_clean)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db26c1",
   "metadata": {},
   "source": [
    "## Partie 4 : Design du Schéma et Insertion dans InfluxDB\n",
    "\n",
    "Comprendre comment choisir entre tags et fields, puis insérer les données efficacement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2jnu9w5r947",
   "metadata": {},
   "source": [
    "### 4.1 Décisions de Design : Tags vs Fields\n",
    "\n",
    "Rappel de la règle :\n",
    "- Tags = filtres fréquents + cardinalité raisonnable\n",
    "- Fields = valeurs mesurées + pas de filtrage\n",
    "\n",
    "Analysons chaque colonne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "el8t5lm3qm5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de décision Tag vs Field \n",
    "import pandas as pd\n",
    "\n",
    "decisions = [\n",
    "    {\n",
    "        \"Colonne\": \"timestamp\",\n",
    "        \"Cardinalité\": df_clean['timestamp'].nunique(),\n",
    "        \"Type\": \"TIMESTAMP\",\n",
    "        \"Décision\": \"Timestamp InfluxDB\",\n",
    "        \"Raison\": \"Index temporel principal\"\n",
    "    },\n",
    "    {\n",
    "        \"Colonne\": \"individual-local-identifier\",\n",
    "        \"Cardinalité\": df_clean['individual-local-identifier'].nunique(),\n",
    "        \"Type\": \"TAG\",\n",
    "        \"Décision\": \"Tag\",\n",
    "        \"Raison\": \"Filtrage fréquent par oiseau, ~199 valeurs (cardinalité ok)\"\n",
    "    },\n",
    "    {\n",
    "        \"Colonne\": \"tag-local-identifier\",\n",
    "        \"Cardinalité\": df_clean['tag-local-identifier'].nunique(),\n",
    "        \"Type\": \"TAG\",\n",
    "        \"Décision\": \"Tag\",\n",
    "        \"Raison\": \"Filtrage par device, ~199 valeurs (cardinalité ok)\"\n",
    "    },\n",
    "    {\n",
    "        \"Colonne\": \"sensor-type\",\n",
    "        \"Cardinalité\": df_clean['sensor-type'].nunique(),\n",
    "        \"Type\": \"FIELD\",\n",
    "        \"Décision\": \"Field (anti-pattern si tag)\",\n",
    "        \"Raison\": \"CARDINALITÉ = 1 ! Index inutile, gaspillage mémoire\"\n",
    "    },\n",
    "    {\n",
    "        \"Colonne\": \"individual-taxon-canonical-name\",\n",
    "        \"Cardinalité\": df_clean['individual-taxon-canonical-name'].nunique(),\n",
    "        \"Type\": \"FIELD\",\n",
    "        \"Décision\": \"Field\",\n",
    "        \"Raison\": \"Cardinalité = 1 (tous Larus fuscus), même raison\"\n",
    "    },\n",
    "    {\n",
    "        \"Colonne\": \"study-name\",\n",
    "        \"Cardinalité\": df_clean['study-name'].nunique(),\n",
    "        \"Type\": \"FIELD\",\n",
    "        \"Décision\": \"Field\",\n",
    "        \"Raison\": \"Cardinalité = 1, pas de filtrage nécessaire\"\n",
    "    },\n",
    "    {\n",
    "        \"Colonne\": \"event-id\",\n",
    "        \"Cardinalité\": df_clean['event-id'].nunique(),\n",
    "        \"Type\": \"FIELD\",\n",
    "        \"Décision\": \"Field\",\n",
    "        \"Raison\": \"Cardinalité = 89867 (unique), jamais en tag!\"\n",
    "    },\n",
    "    {\n",
    "        \"Colonne\": \"location-lat\",\n",
    "        \"Cardinalité\": df_clean['location-lat'].nunique(),\n",
    "        \"Type\": \"FIELD\",\n",
    "        \"Décision\": \"Field\",\n",
    "        \"Raison\": \"Valeur mesurée (coordonnée GPS)\"\n",
    "    },\n",
    "    {\n",
    "        \"Colonne\": \"location-long\",\n",
    "        \"Cardinalité\": df_clean['location-long'].nunique(),\n",
    "        \"Type\": \"FIELD\",\n",
    "        \"Décision\": \"Field\",\n",
    "        \"Raison\": \"Valeur mesurée (coordonnée GPS)\"\n",
    "    },\n",
    "    {\n",
    "        \"Colonne\": \"vegetation_cover_low\",\n",
    "        \"Cardinalité\": df_clean['vegetation_cover_low'].nunique(),\n",
    "        \"Type\": \"FIELD\",\n",
    "        \"Décision\": \"Field\",\n",
    "        \"Raison\": \"Valeur mesurée (donnée environnementale)\"\n",
    "    },\n",
    "    {\n",
    "        \"Colonne\": \"vegetation_cover_high\",\n",
    "        \"Cardinalité\": df_clean['vegetation_cover_high'].nunique(),\n",
    "        \"Type\": \"FIELD\",\n",
    "        \"Décision\": \"Field\",\n",
    "        \"Raison\": \"Valeur mesurée (donnée environnementale)\"\n",
    "    },\n",
    "    {\n",
    "        \"Colonne\": \"visible / visible.1\",\n",
    "        \"Cardinalité\": df_clean['visible'].nunique(),\n",
    "        \"Type\": \"FIELD\",\n",
    "        \"Décision\": \"Field\",\n",
    "        \"Raison\": \"Métadonnée booléenne, pas de filtrage\"\n",
    "    }\n",
    "]\n",
    "\n",
    "decision_df = pd.DataFrame(decisions)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"MATRICE DE DÉCISION : TAGS vs FIELDS\".center(100))\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Colonne':<35} {'Card.':>10} {'Type':^20} {'Raison':<30}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for _, row in decision_df.iterrows():\n",
    "    print(f\"{row['Colonne']:<35} {row['Cardinalité']:>10,} {row['Type']:^20} {row['Raison']:<30}\")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print()\n",
    "print(\"RÉSUMÉ DU SCHÉMA:\")\n",
    "print(f\"  Tags (2)   : individual-local-identifier, tag-local-identifier\")\n",
    "print(f\"  Fields (9) : location-lat, location-long, event-id, vegetation_cover_*, etc.\")\n",
    "print(f\"  Timestamp  : timestamp\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2taaq8zbjun",
   "metadata": {},
   "source": [
    "### 4.2 Anti-Patterns à Éviter\n",
    "\n",
    "NE PAS mettre en tags :\n",
    "- Colonnes avec cardinalité = 1 (constantes) → gaspillage mémoire\n",
    "- Colonnes avec haute cardinalité (> 100k) → explosion des index\n",
    "- Timestamps → utiliser le timestamp InfluxDB\n",
    "- Floats avec haute cardinalité → utiliser fields\n",
    "\n",
    "Notre schéma optimisé : 2 tags (~199 valeurs chacun), reste en fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rns0at7byus",
   "metadata": {},
   "source": [
    "### 4.3 Insertion des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['timestamp'] = pd.to_datetime(df_clean['timestamp'])\n",
    "\n",
    "print(f\"Insertion de {len(df_clean):,} records dans InfluxDB...\")\n",
    "print(f\"Tags: individual-local-identifier, tag-local-identifier\")\n",
    "print(f\"Fields: {df_clean.shape[1] - 3} colonnes\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    write_api.write(\n",
    "        bucket=INFLUX_BUCKET, \n",
    "        org=INFLUX_ORG, \n",
    "        record=df_clean, \n",
    "        data_frame_measurement_name='bird_migration',\n",
    "        data_frame_tag_columns=[\n",
    "            'individual-local-identifier',\n",
    "            'tag-local-identifier',\n",
    "        ],\n",
    "        data_frame_timestamp_column='timestamp'\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nInsertion réussie en {elapsed:.2f}s ({len(df_clean)/elapsed:.0f} points/s)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qe3v2yymgy",
   "metadata": {},
   "source": [
    "### 4.4 Vérification de l'Insertion\n",
    "\n",
    "Vérifions que les données ont bien été insérées dans InfluxDB en exécutant une requête simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4lw2p0ip4h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification simple : récupérer quelques points\n",
    "verification_query = f'''\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: 0)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "  |> limit(n: 10)\n",
    "'''\n",
    "\n",
    "result = query_api.query_data_frame(verification_query, org=INFLUX_ORG)\n",
    "\n",
    "# Traiter le résultat\n",
    "if isinstance(result, list) and len(result) > 0:\n",
    "    result_df = pd.concat(result, ignore_index=True)\n",
    "    print(f\"Données trouvées: {len(result_df)} lignes\")\n",
    "    print(result_df.head())\n",
    "elif isinstance(result, pd.DataFrame) and len(result) > 0:\n",
    "    print(f\"Données trouvées: {len(result)} lignes\")\n",
    "    print(result.head())\n",
    "else:\n",
    "    print(\"Aucune donnée trouvée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63448e93",
   "metadata": {},
   "source": [
    "## Partie 5 : Langage de Requêtes Flux - Construction Progressive\n",
    "\n",
    "Maîtriser Flux en construisant des requêtes de plus en plus complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee603b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function pour afficher les résultats Flux proprement\n",
    "def display_flux_result(result, title=\"Résultat\"):\n",
    "    \"\"\"Affiche les résultats d'une requête Flux de manière lisible\"\"\"\n",
    "    if isinstance(result, list):\n",
    "        if len(result) > 0:\n",
    "            result_df = pd.concat(result, ignore_index=True)\n",
    "            print(f\"{title}: {len(result_df)} lignes\")\n",
    "            display(result_df.head(10))\n",
    "            return result_df\n",
    "        else:\n",
    "            print(f\"{title}: Aucune donnée\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"{title}: {len(result)} lignes\")\n",
    "        if len(result) > 0:\n",
    "            display(result.head(10))\n",
    "        return result\n",
    "\n",
    "def process_flux_result(result):\n",
    "    \"\"\"Convertit le résultat Flux en DataFrame\"\"\"\n",
    "    if isinstance(result, list) and len(result) > 0:\n",
    "        return pd.concat(result, ignore_index=True)\n",
    "    return result if isinstance(result, pd.DataFrame) else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yj43zoxe83",
   "metadata": {},
   "source": [
    "### 5.1 Requête de Base : Récupérer des Données\n",
    "\n",
    "Anatomie d'une requête Flux :\n",
    "```\n",
    "from(bucket: \"nom\")              ← Source des données\n",
    "  |> range(start: xxx, stop: yyy)  ← Filtre temporel (OBLIGATOIRE)\n",
    "  |> filter(fn: (r) => ...)        ← Filtres supplémentaires\n",
    "  |> limit(n: 10)                  ← Limiter le nombre de résultats\n",
    "```\n",
    "\n",
    "Pipeline : Chaque opérateur `|>` passe les données à l'opérateur suivant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86zs6l0lu9q",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requête 1: Récupérer les 100 premiers points\n",
    "query_basic = f'''\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: 0)  \n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "  |> limit(n: 100)\n",
    "'''\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"REQUÊTE 1: RÉCUPÉRATION BASIQUE (100 premiers points)\".center(80))\n",
    "print(\"=\" * 80)\n",
    "print(query_basic)\n",
    "print()\n",
    "\n",
    "result_basic = query_api.query_data_frame(query_basic, org=INFLUX_ORG)\n",
    "df_basic = display_flux_result(result_basic, \"Requête basique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fvqivilwe2f",
   "metadata": {},
   "source": [
    "### 5.2 Filtrage par Tag : Requêtes Efficaces\n",
    "\n",
    "Pourquoi filtrer sur les tags : Index optimisés → queries ultra-rapides\n",
    "\n",
    "Équivalence :\n",
    "- Flux : `filter(fn: (r) => r[\"individual-local-identifier\"] == \"91732A\")`\n",
    "- SQL : `WHERE individual_local_identifier = '91732A'`\n",
    "- Pandas : `df[df['individual-local-identifier'] == '91732A']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stz2u744psj",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_id = \"91732A\"\n",
    "\n",
    "query_by_bird = f'''\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: 0)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "  |> filter(fn: (r) => r[\"individual-local-identifier\"] == \"{bird_id}\")\n",
    "  |> limit(n: 50)\n",
    "'''\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"REQUÊTE 2: FILTRAGE PAR TAG (oiseau {bird_id})\".center(80))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result_by_bird = query_api.query_data_frame(query_by_bird, org=INFLUX_ORG)\n",
    "df_by_bird = display_flux_result(result_by_bird, f\"Données pour {bird_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2mxs5iwpu8y",
   "metadata": {},
   "source": [
    "### 5.3 Filtrage Temporel : La Force des Time-Series DB\n",
    "\n",
    "C'est ici que InfluxDB brille : requêtes temporelles ultra-optimisées\n",
    "\n",
    "Exemple : Trouver les données de migration estivale (juin-août 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yyt29jonjpi",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_summer = f'''\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: 2009-06-01T00:00:00Z, stop: 2009-08-31T23:59:59Z)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"location-lat\")\n",
    "  |> limit(n: 100)\n",
    "'''\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"REQUÊTE 3: FILTRAGE TEMPOREL (été 2009)\".center(80))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result_summer = query_api.query_data_frame(query_summer, org=INFLUX_ORG)\n",
    "df_summer = display_flux_result(result_summer, \"Données été 2009\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qdt2tp6cm6",
   "metadata": {},
   "source": [
    "### 5.4 Restructuration avec Pivot : Transformer Fields en Colonnes\n",
    "\n",
    "Problème : InfluxDB retourne 1 ligne par field → difficile à analyser\n",
    "\n",
    "Solution : `pivot()` transforme les fields en colonnes (comme un DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l8k9y6oe32h",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pivot = f'''\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: 0)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "  |> filter(fn: (r) => r[\"individual-local-identifier\"] == \"91732A\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"location-lat\" or r[\"_field\"] == \"location-long\")\n",
    "  |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "  |> limit(n: 20)\n",
    "'''\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"REQUÊTE 4: PIVOT (fields → colonnes)\".center(80))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result_pivot = query_api.query_data_frame(query_pivot, org=INFLUX_ORG)\n",
    "df_pivot = display_flux_result(result_pivot, \"Données pivotées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ozincr4ck5b",
   "metadata": {},
   "source": [
    "### 5.5 Agrégation : Compter, Grouper, Analyser\n",
    "\n",
    "Opérations d'agrégation courantes :\n",
    "- `count()` : nombre de points\n",
    "- `mean()` : moyenne\n",
    "- `sum()` : somme\n",
    "- `max()` / `min()` : valeurs extrêmes\n",
    "- `group()` : grouper par tag(s)\n",
    "\n",
    "Exemple : Compter le nombre de tracking points par oiseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7yaew54pbrc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_count = f'''\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: 0)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"location-lat\")\n",
    "  |> group(columns: [\"individual-local-identifier\"])\n",
    "  |> count()\n",
    "  |> sort(columns: [\"_value\"], desc: true)\n",
    "  |> limit(n: 20)\n",
    "'''\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"REQUÊTE 5: AGRÉGATION (count par oiseau)\".center(80))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result_count = query_api.query_data_frame(query_count, org=INFLUX_ORG)\n",
    "df_count = display_flux_result(result_count, \"Comptage par oiseau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wporpri0qe",
   "metadata": {},
   "source": [
    "### 5.6 Window Functions : Agrégation Temporelle\n",
    "\n",
    "Cas d'usage : Calculer des moyennes par jour/heure/mois\n",
    "\n",
    "`aggregateWindow()` divise le temps en fenêtres et agrège chacune séparément"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "glaesy6fgrk",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_window = f'''\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: 2009-05-01T00:00:00Z, stop: 2009-05-31T23:59:59Z)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"vegetation_cover_high\")\n",
    "  |> aggregateWindow(every: 1d, fn: mean, createEmpty: false)\n",
    "  |> limit(n: 31)\n",
    "'''\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"REQUÊTE 6: WINDOW FUNCTION (moyenne journalière)\".center(80))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result_window = query_api.query_data_frame(query_window, org=INFLUX_ORG)\n",
    "df_window = display_flux_result(result_window, \"Moyenne quotidienne végétation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ajn37athxa",
   "metadata": {},
   "source": [
    "## Partie 6 : Visualisations - Démonstration (OPTIONNEL)\n",
    "\n",
    "Note : Cette partie est une démonstration optionnelle pour montrer ce qu'on peut faire avec les données. L'objectif principal du TP est d'apprendre InfluxDB (schema design, Flux queries), pas la visualisation de données.\n",
    "\n",
    "Montrer rapidement quelques visualisations possibles des patterns de migration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cixzzzysn25",
   "metadata": {},
   "source": [
    "### 6.1 Carte Interactive des Routes de Migration\n",
    "\n",
    "Visualiser les trajectoires des 3 oiseaux les plus trackés sur une carte interactive avec Folium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ftsurtfmh8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_top_birds = f'''\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: 0)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"location-lat\")\n",
    "  |> group(columns: [\"individual-local-identifier\"])\n",
    "  |> count()\n",
    "  |> group()\n",
    "  |> sort(columns: [\"_value\"], desc: true)\n",
    "  |> limit(n: 3)\n",
    "'''\n",
    "\n",
    "result_top = query_api.query_data_frame(query_top_birds, org=INFLUX_ORG)\n",
    "df_top = process_flux_result(result_top)\n",
    "\n",
    "# S'assurer qu'on a bien seulement 3 oiseaux\n",
    "if df_top is not None and len(df_top) > 3:\n",
    "    df_top = df_top.head(3)\n",
    "\n",
    "top_bird_ids = df_top['individual-local-identifier'].tolist()\n",
    "\n",
    "print(f\"Top 3 oiseaux: {', '.join(top_bird_ids)}\")\n",
    "\n",
    "m = folium.Map(location=[50, 15], zoom_start=4, tiles='OpenStreetMap')\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "for idx, bird_id in enumerate(top_bird_ids):\n",
    "    query_traj = f'''\n",
    "    from(bucket: \"{INFLUX_BUCKET}\")\n",
    "      |> range(start: 0)\n",
    "      |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "      |> filter(fn: (r) => r[\"individual-local-identifier\"] == \"{bird_id}\")\n",
    "      |> filter(fn: (r) => r[\"_field\"] == \"location-lat\" or r[\"_field\"] == \"location-long\")\n",
    "      |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "      |> sort(columns: [\"_time\"])\n",
    "    '''\n",
    "    \n",
    "    result_traj = query_api.query_data_frame(query_traj, org=INFLUX_ORG)\n",
    "    df_traj = process_flux_result(result_traj)\n",
    "    \n",
    "    if df_traj is not None and len(df_traj) > 0:\n",
    "        # Filtrer les lignes avec des valeurs NaN\n",
    "        df_traj = df_traj.dropna(subset=['location-lat', 'location-long'])\n",
    "        \n",
    "        if len(df_traj) > 0:  # Vérifier à nouveau après le dropna\n",
    "            points = list(zip(df_traj['location-lat'], df_traj['location-long']))\n",
    "            \n",
    "            if len(points) > 0:  # Vérifier que points n'est pas vide\n",
    "                from folium.plugins import AntPath\n",
    "                AntPath(points, color=colors[idx], weight=2.5, opacity=0.8, delay=800,\n",
    "                        popup=f\"<b>{bird_id}</b><br>{len(points)} points\").add_to(m)\n",
    "                \n",
    "                folium.Marker(points[0], popup=f\"Départ: {bird_id}\",\n",
    "                             icon=folium.Icon(color=colors[idx], icon='play')).add_to(m)\n",
    "                folium.Marker(points[-1], popup=f\"Fin: {bird_id}\",\n",
    "                             icon=folium.Icon(color=colors[idx], icon='stop')).add_to(m)\n",
    "            else:\n",
    "                print(f\"Aucun point valide pour l'oiseau {bird_id}\")\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9xzsccgjco6",
   "metadata": {},
   "source": [
    "### 6.2 Time-Series: Latitude au Fil du Temps\n",
    "\n",
    "Visualiser le pattern de migration saisonnière d'un oiseau (latitude vs temps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ajgt7ekcv1w",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_bird = top_bird_ids[0]\n",
    "\n",
    "query_lat_time = f'''\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: 0)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "  |> filter(fn: (r) => r[\"individual-local-identifier\"] == \"{main_bird}\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"location-lat\")\n",
    "  |> sort(columns: [\"_time\"])\n",
    "'''\n",
    "\n",
    "result_lat = query_api.query_data_frame(query_lat_time, org=INFLUX_ORG)\n",
    "df_lat = process_flux_result(result_lat)\n",
    "\n",
    "if df_lat is not None and len(df_lat) > 0:\n",
    "    df_lat['_time'] = pd.to_datetime(df_lat['_time'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "    ax.plot(df_lat['_time'], df_lat['_value'], linewidth=1.5, color='#2E86AB', alpha=0.8)\n",
    "    \n",
    "    years = df_lat['_time'].dt.year.unique()\n",
    "    for year in years:\n",
    "        summer_start = pd.Timestamp(f'{year}-06-01')\n",
    "        summer_end = pd.Timestamp(f'{year}-08-31')\n",
    "        ax.axvspan(summer_start, summer_end, alpha=0.2, color='yellow', \n",
    "                   label='Été' if year == years[0] else '')\n",
    "        \n",
    "        winter_start = pd.Timestamp(f'{year}-12-01')\n",
    "        winter_end = pd.Timestamp(f'{year+1}-02-28')\n",
    "        ax.axvspan(winter_start, winter_end, alpha=0.2, color='lightblue',\n",
    "                   label='Hiver' if year == years[0] else '')\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Latitude (°)', fontsize=12)\n",
    "    ax.set_title(f'Pattern de Migration: {main_bird}', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Aucune donnée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9vubp0b8e",
   "metadata": {},
   "source": [
    "### 6.3 Heatmap: Densité des Points de Tracking en Fonction du Temps\n",
    "\n",
    "Visualiser l'évolution temporelle des zones de présence des oiseaux (migration saisonnière)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ow2qcxpa8h",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_all_points = f'''\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: 0)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"location-lat\" or r[\"_field\"] == \"location-long\")\n",
    "  |> sample(n: 1000)\n",
    "  |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "'''\n",
    "\n",
    "result_all = query_api.query_data_frame(query_all_points, org=INFLUX_ORG)\n",
    "df_all = process_flux_result(result_all)\n",
    "\n",
    "if df_all is not None and len(df_all) > 0:\n",
    "    from folium.plugins import HeatMap\n",
    "    \n",
    "    # Filtrer les lignes avec des valeurs NaN dans les coordonnées\n",
    "    df_all_clean = df_all.dropna(subset=['location-lat', 'location-long'])\n",
    "    \n",
    "    if len(df_all_clean) > 0:\n",
    "        m_heat = folium.Map(location=[45, 15], zoom_start=4, tiles='CartoDB positron')\n",
    "        heat_data = [[row['location-lat'], row['location-long']] for idx, row in df_all_clean.iterrows()]\n",
    "        \n",
    "        HeatMap(heat_data, radius=8, blur=10, max_zoom=6,\n",
    "                gradient={0.4: 'blue', 0.65: 'lime', 0.8: 'yellow', 1.0: 'red'}).add_to(m_heat)\n",
    "        \n",
    "        print(f\"Heatmap: {len(heat_data):,} points\")\n",
    "        display(m_heat)\n",
    "    else:\n",
    "        print(\"Aucune donnée valide après nettoyage des NaN\")\n",
    "else:\n",
    "    print(\"Aucune donnée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qwt36u3q1w9",
   "metadata": {},
   "source": [
    "### 6.4 Corrélation: Latitude vs Couverture Végétale\n",
    "\n",
    "Y a-t-il une corrélation entre la latitude (zones géographiques) et la végétation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee98mqpz76h",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_veg = f'''\n",
    "from(bucket: \"{INFLUX_BUCKET}\")\n",
    "  |> range(start: 0)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"bird_migration\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"vegetation_cover_high\" or r[\"_field\"] == \"vegetation_cover_low\" or r[\"_field\"] == \"location-lat\")\n",
    "  |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "  |> limit(n: 1000)\n",
    "'''\n",
    "\n",
    "result_veg = query_api.query_data_frame(query_veg, org=INFLUX_ORG)\n",
    "df_veg = process_flux_result(result_veg)\n",
    "\n",
    "if df_veg is not None and len(df_veg) > 0:\n",
    "    # Nettoyer les données en supprimant les lignes avec des NaN\n",
    "    df_veg_clean = df_veg.dropna(subset=['location-lat', 'vegetation_cover_high', 'vegetation_cover_low'])\n",
    "    \n",
    "    if len(df_veg_clean) > 0:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        ax1.scatter(df_veg_clean['location-lat'], df_veg_clean['vegetation_cover_high'], \n",
    "                    alpha=0.3, s=2, color='#2E7D32')\n",
    "        ax1.set_xlabel('Latitude (°)', fontsize=11)\n",
    "        ax1.set_ylabel('Haute Végétation', fontsize=11)\n",
    "        ax1.set_title('Latitude vs Haute Végétation', fontsize=13, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        corr_high = df_veg_clean['location-lat'].corr(df_veg_clean['vegetation_cover_high'])\n",
    "        ax1.text(0.05, 0.95, f'Corr: {corr_high:.3f}', transform=ax1.transAxes, \n",
    "                 fontsize=10, verticalalignment='top',\n",
    "                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        \n",
    "        ax2.scatter(df_veg_clean['location-lat'], df_veg_clean['vegetation_cover_low'], \n",
    "                    alpha=0.3, s=2, color='#F57C00')\n",
    "        ax2.set_xlabel('Latitude (°)', fontsize=11)\n",
    "        ax2.set_ylabel('Basse Végétation', fontsize=11)\n",
    "        ax2.set_title('Latitude vs Basse Végétation', fontsize=13, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        corr_low = df_veg_clean['location-lat'].corr(df_veg_clean['vegetation_cover_low'])\n",
    "        ax2.text(0.05, 0.95, f'Corr: {corr_low:.3f}', transform=ax2.transAxes,\n",
    "                 fontsize=10, verticalalignment='top',\n",
    "                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Aucune donnée valide\")\n",
    "else:\n",
    "    print(\"Aucune donnée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ku8ob4a05w",
   "metadata": {},
   "source": [
    "## Fin du TP : Récapitulatif\n",
    "\n",
    "### Ce que nous avons appris :\n",
    "\n",
    "Concepts Time-Series :\n",
    "- Différence entre bases relationnelles, documents, et time-series\n",
    "- Pourquoi InfluxDB pour le tracking GPS et les métriques\n",
    "\n",
    "Schema Design InfluxDB :\n",
    "- Tags vs Fields : la décision la plus critique\n",
    "- Impact de la cardinalité sur les performances\n",
    "- Anti-patterns à éviter (tags constants, haute cardinalité)\n",
    "\n",
    "Langage Flux :\n",
    "- Requêtes basiques (`from`, `range`, `filter`)\n",
    "- Agrégations (`count`, `mean`, `group`)\n",
    "- Window functions pour downsampling\n",
    "- Pivot pour restructurer les données\n",
    "\n",
    "Analyse Time-Series :\n",
    "- Requêtes pour trouver les extremes (min/max)\n",
    "- Détection de patterns saisonniers avec agrégation temporelle\n",
    "- Analyse comparative (été vs hiver)\n",
    "\n",
    "Optimisation & Gestion :\n",
    "- Retention policies pour la gestion du cycle de vie des données\n",
    "- Compression et efficacité du stockage\n",
    "- Impact du schema design sur les performances\n",
    "\n",
    "Visualisations (Démonstration) :\n",
    "- Cartes interactives de migration\n",
    "- Time-series plots\n",
    "- Heatmaps de densité\n",
    "- Analyse de corrélation\n",
    "\n",
    "### InfluxDB vs MongoDB : Quand utiliser quoi ?\n",
    "\n",
    "| Critère | InfluxDB | MongoDB |\n",
    "|---------|----------|---------|\n",
    "| Use case | Métriques, IoT, tracking temporel | Documents flexibles, applications web |\n",
    "| Structure | Tags + Fields + Timestamp | JSON documents |\n",
    "| Queries temporelles | Ultra-rapides | Correct avec indexes |\n",
    "| Compression | 10-20x | Moyenne |\n",
    "| Flexibilité schéma | Tags/Fields fixes | Total freedom |\n",
    "| Relations complexes | Pas adapté | Avec $lookup |\n",
    "\n",
    "Choix pour notre projet :\n",
    "- InfluxDB : données temporelles, tracking GPS, métriques environnementales\n",
    "- MongoDB : aurait fonctionné mais moins efficace pour les requêtes temporelles\n",
    "\n",
    "### Prochaines étapes suggérées :\n",
    "\n",
    "1. Continuous Queries : Pré-calculer des agrégations (downsampling automatique)\n",
    "2. Tasks : Automatiser le traitement de données\n",
    "3. Alerting : Détecter des patterns anormaux (oiseau hors zone attendue)\n",
    "4. Grafana : Dashboards temps-réel pour monitoring\n",
    "5. Sharding & Replication : Scalabilité horizontale pour très gros volumes\n",
    "\n",
    "Ressources :\n",
    "- [Documentation InfluxDB](https://docs.influxdata.com/influxdb/v2.0/)\n",
    "- [Flux Language Guide](https://docs.influxdata.com/flux/v0.x/)\n",
    "- [InfluxDB University](https://university.influxdata.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
